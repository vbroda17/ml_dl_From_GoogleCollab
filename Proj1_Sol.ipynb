{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23yxm6fypuvj"
      },
      "source": [
        "### COSC522 Project 1 - Supervised Learning Using Baysian Decision Rule: Maximum Posterior Probability (MPP)\n",
        "\n",
        "The objective of this project is to learn how to implement supervised learning algorithms based on Baysian decision theory, including both parametric learning (minimum Euclidean distance classifier, minimum Mahalanobis distance classifier, and quadratic machine) and non-parametric learning (k-nearest neighbor).\n",
        "\n",
        "Sample code by Hairong Qi, hqi@utk.edu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygARHRa6puvn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Lsno8KSpuvo"
      },
      "outputs": [],
      "source": [
        "def readprior(s):\n",
        "    \"\"\"Specify the prior probabilities in the following format:\n",
        "    label: value, label: value\"\"\"\n",
        "    priors = {}\n",
        "    pairs = s.strip().split(',')\n",
        "    tot = 0\n",
        "    for ele in pairs:\n",
        "        i, p = ele.strip().split(\":\")\n",
        "        priors[int(i)] = float(p)\n",
        "        tot += float(p)\n",
        "    if tot != 1.0:\n",
        "        raise ValueError(f\"aggregate p is {tot}, expect 1\")\n",
        "\n",
        "    return priors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PntPsGwPpuvo"
      },
      "outputs": [],
      "source": [
        "def load_data(f):\n",
        "    \"\"\" Assume data format:\n",
        "    feature1 feature 2 ... label\n",
        "    \"\"\"\n",
        "    # process training data\n",
        "    data = np.genfromtxt(f)\n",
        "    # return all feature columns except last\n",
        "    X = data[:, :-1]\n",
        "    y = data[:, -1].astype(int)\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_sBsXDypuvp"
      },
      "outputs": [],
      "source": [
        "def normalize(Tr, Te):\n",
        "    \"\"\"Normalize the training set and use the derived statistics to normalize the test set.\n",
        "    \"\"\"\n",
        "    trMean = np.mean(Tr, axis = 0)\n",
        "    trStd = np.std(Tr, axis = 0)\n",
        "    Tr = (Tr - trMean) / trStd\n",
        "    Te = (Te - trMean) / trStd\n",
        "\n",
        "    return Tr, Te"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ollUWF-4puvp"
      },
      "outputs": [],
      "source": [
        "def accuracy_score(y, y_model):\n",
        "    \"\"\" Return accuracy score in both overall and classwise manners.\n",
        "    y: ground-truth label\n",
        "    y_model: predicted label\n",
        "    \"\"\"\n",
        "    assert len(y) == len(y_model)\n",
        "\n",
        "    classn = len(np.unique(y))    # number of different classes\n",
        "    correct_all = y == y_model    # all correctly classified samples\n",
        "\n",
        "    acc_overall = np.sum(correct_all) / len(y)\n",
        "    acc_i = []        # this list stores classwise accuracy\n",
        "\n",
        "    # calculate classwise accuracy\n",
        "    for i in range(classn):\n",
        "        GT_i = y == i            # samples actually belong to class i\n",
        "        acc_i.append(np.sum(GT_i & correct_all) / np.sum(GT_i))\n",
        "\n",
        "    return acc_i, acc_overall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVKZN6ZOpuvp"
      },
      "outputs": [],
      "source": [
        "class mpp:\n",
        "    \"\"\"Maximum Posterior Probability\n",
        "    Supervised parametric learning assuming Gaussian pdf\n",
        "    with 3 cases of discriminant functions. Cases should be 1, 2, or 3.\n",
        "    \"\"\"\n",
        "    def __init__(self, case):\n",
        "        self.case_ = case\n",
        "\n",
        "    def fit(self, Tr, y):\n",
        "        # derive the model\n",
        "        self.covs_, self.means_ = {}, {}     # dictionaries\n",
        "        self.classes_ = np.unique(y)         # get unique labels as dictionary items\n",
        "        self.classn_ = len(self.classes_)    # the number of classes in the dataset\n",
        "        self.dimension_ = np.shape(Tr)[1]\n",
        "\n",
        "        self.covsum_ = 0\n",
        "        for c in self.classes_:\n",
        "            arr = Tr[y == c]\n",
        "            self.covs_[c] = np.cov(np.transpose(arr))\n",
        "            self.means_[c] = np.mean(arr, axis=0)  # mean along rows\n",
        "            self.covsum_ += self.covs_[c]\n",
        "\n",
        "        # used by case II\n",
        "        self.covavg_ = self.covsum_ / self.classn_\n",
        "\n",
        "        # used by case I\n",
        "        self.varavg_ = np.sum(np.diagonal(self.covavg_)) / self.dimension_\n",
        "\n",
        "    def predict(self, Te, prior):\n",
        "        # predict labels of all test data\n",
        "        disc = np.zeros(self.classn_)\n",
        "        nr, _ = Te.shape\n",
        "        y = np.zeros(nr)         # array to hold the predicted label\n",
        "\n",
        "        for i in range(nr):         # going through each sample (or each row of the test set)\n",
        "            for c in self.classes_:  # going through each class or category\n",
        "                if self.case_ == 1:\n",
        "                    edist2 = np.dot(Te[i]-self.means_[c], Te[i]-self.means_[c])\n",
        "                    disc[c] = -edist2 / (2 * self.varavg_) + np.log(prior[c])\n",
        "                elif self.case_ == 2:\n",
        "                    diff = Te[i] - self.means_[c]\n",
        "                    mdist2 = np.dot(np.dot(diff, np.linalg.inv(self.covavg_)), diff)\n",
        "                    disc[c] = -mdist2 / 2 + np.log(prior[c])\n",
        "                elif self.case_ == 3:\n",
        "                    diff = Te[i] - self.means_[c]\n",
        "                    mdist2 = np.dot(np.dot(diff, np.linalg.inv(self.covs_[c])), diff)\n",
        "                    disc[c] = -mdist2 / 2 - np.log(np.linalg.det(self.covs_[c])) / 2 + np.log(prior[c])\n",
        "                else:\n",
        "                    print(\"Can only handle case numbers 1, 2, 3.\")\n",
        "                    sys.exit(1)\n",
        "            y[i] = disc.argmax() # note that I did not use randomness in the tie situation\n",
        "\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFXbpCN6puvq"
      },
      "outputs": [],
      "source": [
        "def knn(Tr, yTr, Te, k):\n",
        "    \"\"\" k-Nearest Neighbor (kNN)\n",
        "    Supervised non-parametric learning not assuming any pdf model\n",
        "    \"\"\"\n",
        "    classes = np.unique(yTr)   # get unique labels as dictionary items\n",
        "    classn = len(classes)      # number of classes\n",
        "    ntr, _ = Tr.shape\n",
        "    nte, _ = Te.shape\n",
        "\n",
        "    y = np.zeros(nte)\n",
        "    knn_count = np.zeros(classn)\n",
        "    for i in range(nte):\n",
        "        test = np.tile(Te[i,:], (ntr, 1))       # resembles MATLAB's repmat function\n",
        "        dist = np.sum((test - Tr) ** 2, axis = 1) # calculate distance\n",
        "        idist = np.argsort(dist)    # sort the array in the ascending order and return the index\n",
        "        knn_label = yTr[idist[0:k]]\n",
        "        for c in range(classn):\n",
        "            knn_count[c] = np.sum(knn_label == c)\n",
        "        y[i] = np.argmax(knn_count)\n",
        "\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymIXahSkpuvr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "outputId": "7b55ee9b-02c4-4397-a234-4ad557220c0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Case\t Acc_Overall\t Acc_Classwise\t\t Runtime\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-acc856fe557e>:19: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  self.covs_[c] = np.cov(np.transpose(arr))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-703d11d6153e>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m                  \u001b[0;31m# train the model using the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0my_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# test the model using the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0macc_classwise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_overall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_model\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# evaluate the performance of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-acc856fe557e>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, Te, prior)\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcase_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0medist2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                     \u001b[0mdisc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0medist2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvaravg_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcase_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: -9223372036854775808"
          ]
        }
      ],
      "source": [
        "\n",
        "# read in the datasets\n",
        "Xtrain, ytrain = load_data('/content/synth.tr')\n",
        "Xtest, ytest = load_data('/content/synth.te')\n",
        "\n",
        "    # specify the prior probabilities\n",
        "prior = readprior(\"0:0.5, 1:0.5\")\n",
        "\n",
        "    # normalize datasets (synth is normalized already, no need to do it again)\n",
        "    #Xtrain, Xtest = normalize(Xtrain, Xtest)\n",
        "\n",
        "    # prepare the meshgrid for plotting the decision boundary\n",
        "res = 100\n",
        "x = np.linspace(np.min(Xtest[:, 0]), np.max(Xtest[:, 0]), res)\n",
        "y = np.linspace(np.min(Xtest[:, 1]), np.max(Xtest[:, 1]), res)\n",
        "X, Y = np.meshgrid(x, y)\n",
        "XY = np.column_stack([X.flat, Y.flat])\n",
        "\n",
        "    # test parametric learning\n",
        "print(f'Case\\t Acc_Overall\\t Acc_Classwise\\t\\t Runtime')\n",
        "for cases in [1, 2, 3]:\n",
        "    model = mpp(cases)                         # a new model\n",
        "    t0 = time.time()\n",
        "    model.fit(Xtrain, ytrain)                  # train the model using the training set\n",
        "    y_model = model.predict(Xtest, prior)      # test the model using the test set\n",
        "    t1 = time.time()\n",
        "    acc_classwise, acc_overall = accuracy_score(ytest, y_model)   # evaluate the performance of the model\n",
        "    print(f'{cases}\\t{acc_overall:.3f}\\t\\t{acc_classwise[0]:.3f}\\t{acc_classwise[1]:.3f} \\t\\t{(t1 - t0):.4f}')\n",
        "\n",
        "    y_boundary = model.predict(XY, prior)\n",
        "\n",
        "    # plot the decision boundary: do the scatter plot of the test set\n",
        "    plt.figure(cases)\n",
        "    arr = XY[y_boundary == 0]\n",
        "    plt.scatter(arr[:, 0], arr[:, 1], c = \"xkcd:light blue\")\n",
        "    arr = XY[y_boundary == 1]\n",
        "    plt.scatter(arr[:, 0], arr[:, 1], c = \"xkcd:light pink\")\n",
        "\n",
        "    arr = Xtest[ytest == 0]\n",
        "    plt.scatter(arr[:, 0], arr[:, 1], c = \"xkcd:blue\")\n",
        "    arr = Xtest[ytest == 1]\n",
        "    plt.scatter(arr[:, 0], arr[:, 1], c = \"xkcd:red\")\n",
        "\n",
        "    # test non-parametric learning\n",
        "print(f'kNN is going through all potential k values for the best overall accuracy ...')\n",
        "k_acc = []\n",
        "avg_time = 0\n",
        "ntr, _ = Xtrain.shape\n",
        "for k in range(ntr):            # exhaustive search for the k value that results in the best overall accuracy\n",
        "    t0 = time.time()\n",
        "    y_model = knn(Xtrain, ytrain, Xtest, k + 1)\n",
        "    t1 = time.time()\n",
        "    avg_time += t1 - t0\n",
        "    acc_classwise, acc_overall = accuracy_score(ytest, y_model)   # evaluate the performance of the model\n",
        "\n",
        "    if k == 0:\n",
        "        acc_classwise_highest = acc_classwise\n",
        "        acc_overall_highest = acc_overall\n",
        "        k_highest = k + 1\n",
        "    else:\n",
        "        if acc_overall_highest < acc_overall:\n",
        "            acc_classwise_highest = acc_classwise\n",
        "            acc_overall_highest = acc_overall\n",
        "            k_highest = k + 1\n",
        "    k_acc.append(acc_overall)\n",
        "avg_time /= ntr\n",
        "print(f'k={k_highest}\\t{acc_overall_highest:.3f}\\t\\t{acc_classwise_highest[0]:.3f}\\t{acc_classwise_highest[1]:.3f} \\t\\t{avg_time:.4f}')\n",
        "\n",
        "# plot acc_overall vs. k\n",
        "index = np.arange(1, ntr + 1)      # so that the plot starts at k=1 not k=0\n",
        "plt.figure(4)\n",
        "plt.plot(index, k_acc)\n",
        "plt.ylabel('Overall Accuracy')\n",
        "plt.xlabel('k')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5S3PLA6uAbQI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}